{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report Analysis Synthetic Cluster=10 (replicates)\n",
    "\n",
    "This notebook creates the synthetic experiment RMSE results for the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import halfnorm\n",
    "import math\n",
    "import seaborn as sns\n",
    "import pylab as plt\n",
    "\n",
    "from scipy.special import expit as logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyBasket.preprocessing import get_pivot_count_df\n",
    "from pyBasket.model import get_patient_model_hierarchical_log_odds_nc\n",
    "from pyBasket.model import get_model_simple, get_model_bhm_nc\n",
    "from pyBasket.common import create_if_not_exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define experimental methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    \n",
    "    # Define number of patients, tissues, and clusters\n",
    "    n_patients = 500\n",
    "    n_tissues = 25\n",
    "    n_clusters = 10\n",
    "\n",
    "    # Generate tissue and cluster indices for each patient\n",
    "    basket_coords = np.arange(n_tissues)\n",
    "    cluster_coords = np.arange(n_clusters)\n",
    "    basket_idx = np.random.choice(basket_coords, size=n_patients)\n",
    "    cluster_idx = np.random.choice(cluster_coords, size=n_patients)\n",
    "\n",
    "    # Generate synthetic responsiveness data\n",
    "    theta_basket = np.random.normal(loc=0, scale=2, size=n_tissues)\n",
    "\n",
    "    # Generate unique prior mean and std for each column in theta_cluster\n",
    "    prior_means = np.random.normal(loc=0, scale=2, size=n_clusters)\n",
    "    prior_std_mean = 0 # mean of the half-normal distribution\n",
    "    prior_std_std = 1 # standard deviation of the half-normal distribution\n",
    "    prior_std_scale = np.sqrt(2) * prior_std_std / np.pi\n",
    "    prior_stds = halfnorm.rvs(loc=prior_std_mean, scale=prior_std_scale, size=n_clusters)\n",
    "\n",
    "    theta_cluster = np.zeros((n_tissues, n_clusters))\n",
    "    for i in range(n_clusters):\n",
    "        theta_cluster[:,i] = np.random.normal(loc=prior_means[i], scale=prior_stds[i], size=n_tissues)\n",
    "\n",
    "    true_basket_p = logistic(theta_basket)\n",
    "    true_cluster_p = logistic(theta_cluster)\n",
    "    true_basket_reshaped = true_basket_p.reshape((n_tissues, 1))\n",
    "    true_mat = true_basket_reshaped * true_cluster_p\n",
    "\n",
    "    true_patient_p = true_mat[basket_idx, cluster_idx]\n",
    "    is_responsive = np.random.binomial(n=1, p=true_patient_p)\n",
    "\n",
    "    # Create synthetic data dataframe\n",
    "    data_df = pd.DataFrame({\n",
    "        'basket_number': basket_idx,\n",
    "        'cluster_number': cluster_idx,\n",
    "        'responsive': is_responsive\n",
    "    })\n",
    "\n",
    "    # Print the first few rows of the data dataframe\n",
    "    return data_df, true_basket_p,  true_cluster_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data_df, true_basket_p,  true_cluster_p, n_burn_in=int(5E3), n_sample=int(5E3), target_accept=0.99):\n",
    "    df_pivot = get_pivot_count_df(data_df)\n",
    "    \n",
    "    # Simple model\n",
    "    model_s = get_model_simple(df_pivot)\n",
    "    with model_s:\n",
    "        trace_s = pm.sample(n_sample, tune=n_burn_in, idata_kwargs={'log_likelihood': True}, target_accept=target_accept)\n",
    "    stacked_s = az.extract(trace_s)\n",
    "\n",
    "    # BHM (Berry 2013)\n",
    "    model_bhm = get_model_bhm_nc(df_pivot)\n",
    "    with model_bhm:\n",
    "        trace_h1 = pm.sample(n_sample, tune=n_burn_in, idata_kwargs={'log_likelihood': True}, target_accept=target_accept)\n",
    "    stacked_h1 = az.extract(trace_h1)\n",
    "\n",
    "    # pyBasket\n",
    "    model_h2_nc = get_patient_model_hierarchical_log_odds_nc(data_df)\n",
    "    with model_h2_nc:\n",
    "        trace_h2 = pm.sample(n_sample, tune=n_burn_in, idata_kwargs={'log_likelihood': True}, target_accept=target_accept)\n",
    "    stacked_h2 = az.extract(trace_h2)\n",
    "\n",
    "    # calculate RMSE for basket probabilities\n",
    "    actual = true_basket_p\n",
    "\n",
    "    predicted_basket_s = np.mean(stacked_s.basket_p.values, axis=1)\n",
    "    predicted_basket_h1 = np.mean(stacked_h1.basket_p.values, axis=1)\n",
    "    predicted_basket_h2 = np.mean(stacked_h2.basket_p.values, axis=1)\n",
    "\n",
    "    rmse_s = math.sqrt(mean_squared_error(actual, predicted_basket_s))\n",
    "    rmse_h1 = math.sqrt(mean_squared_error(actual, predicted_basket_h1))\n",
    "    rmse_h2 = math.sqrt(mean_squared_error(actual, predicted_basket_h2))\n",
    "\n",
    "    rmse_basket_p = pd.DataFrame({\n",
    "        'method': ['Simple', 'BHM', 'pyBasket'],\n",
    "        'RMSE': [rmse_s, rmse_h1, rmse_h2]\n",
    "    })\n",
    "\n",
    "    # calculate RMSE for cluster probabilities\n",
    "    actual = true_cluster_p\n",
    "\n",
    "    predicted_cluster_h2 = np.mean(stacked_h2.cluster_p.values, axis=2)\n",
    "    rmse_h2 = math.sqrt(mean_squared_error(actual, predicted_cluster_h2))\n",
    "\n",
    "    rmse_cluster_p = pd.DataFrame({\n",
    "        'method': ['pyBasket'],\n",
    "        'RMSE': [rmse_h2]\n",
    "    })\n",
    "\n",
    "    return rmse_basket_p, rmse_cluster_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = 30\n",
    "n_burn_in=int(5E3)\n",
    "n_sample=int(5E3)\n",
    "\n",
    "all_rmse_basket_p = []\n",
    "all_rmse_cluster_p = []\n",
    "\n",
    "for i in range(repeat):\n",
    "    print(i)\n",
    "    \n",
    "    data_df, true_basket_p,  true_cluster_p = generate_data()\n",
    "    rmse_basket_p, rmse_cluster_p = run_experiment(data_df, true_basket_p,  true_cluster_p, n_burn_in=n_burn_in, n_sample=n_sample)\n",
    "    \n",
    "    all_rmse_basket_p.append(rmse_basket_p)\n",
    "    all_rmse_cluster_p.append(rmse_cluster_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(all_rmse_basket_p) == len(all_rmse_cluster_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_rmse_basket_p)):\n",
    "    basket_df = all_rmse_basket_p[i]\n",
    "    cluster_df = all_rmse_cluster_p[i]\n",
    "    basket_df['repeat'] = i\n",
    "    cluster_df['repeat'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rmse_basket_p_df = pd.concat(all_rmse_basket_p)\n",
    "all_rmse_cluster_p_df = pd.concat(all_rmse_cluster_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rmse_basket_p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rmse_cluster_p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.abspath('results')\n",
    "create_if_not_exist(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rmse_basket_p_df.to_pickle(os.path.join(out_dir, 'all_rmse_basket_p_df.p'))\n",
    "all_rmse_cluster_p_df.to_pickle(os.path.join(out_dir, 'all_rmse_cluster_p_df.p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.abspath('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rmse_basket_p_df = pd.read_pickle(os.path.join(out_dir, 'all_rmse_basket_p_df.p'))\n",
    "all_rmse_cluster_p_df = pd.read_pickle(os.path.join(out_dir, 'all_rmse_cluster_p_df.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(nrows=1, ncols=1, figsize=(7, 7))\n",
    "\n",
    "sns.boxplot(x='method', y='RMSE', data=all_rmse_basket_p_df, ax=ax1)\n",
    "ax1.set_title('Root Mean Squared Error (RMSE) \\n of basket probabilities')\n",
    "plt.xlabel(None)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/report_all_rmse_basket.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(nrows=1, ncols=1, figsize=(7, 7))\n",
    "\n",
    "sns.boxplot(x='method', y='RMSE', data=all_rmse_cluster_p_df, ax=ax1)\n",
    "ax1.set_title('Root Mean Squared Error (RMSE) \\n of cluster probabilities')\n",
    "plt.xlabel(None)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/report_all_rmse_cluster.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "05a318a39bdd806c866a458e5513009c97d8e8627387c5b7a048c974669be487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
